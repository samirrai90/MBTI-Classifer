{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MBTI Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Modelling our MBTI Classifier"
      ],
      "metadata": {
        "id": "qtzW9poixrZc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4hKf0UVqRpGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f363c9d-fac2-4571-dda7-432d19ed50b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n"
          ]
        }
      ],
      "source": [
        "# installs required for gensim\n",
        "!pip install gensim\n",
        "!pip install --upgrade gensim\n",
        "\n",
        "## standard imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for loading dataset via google drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "## sklearn imports\n",
        "# for prepping data\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# countvec & tfidfvec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# classifiers\n",
        "from sklearn.naive_bayes import BernoulliNB, ComplementNB, CategoricalNB, MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# model metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "RBveD_xde9gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## mount google drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvo48tunSOda",
        "outputId": "fb36ebe4-2670-43b3-de76-6e40965ac094"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the current working directory\n",
        "#os.chdir(\"drive/MyDrive/Capstone data \")\n",
        "os.chdir(\"drive/MyDrive/Capstone/data\")"
      ],
      "metadata": {
        "id": "OtYjoxnCSPoZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if unzipping needed\n",
        "#!unzip MBTI_500.zip"
      ],
      "metadata": {
        "id": "kpnzXQPbSTuu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mbti = pd.read_csv('MBTI 500.csv')"
      ],
      "metadata": {
        "id": "NpC-EjCySUP8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mbti.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCPyZS4JSiLK",
        "outputId": "e6b47d62-9bd0-4e74-934e-303b5509a975"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106067, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick Visualistaion of Personality Distribution"
      ],
      "metadata": {
        "id": "tgnOGL9KxaEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mbti.groupby('type').count()"
      ],
      "metadata": {
        "id": "su4F4m6yghKf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "chart = sns.countplot(x=\"type\", data=mbti, palette = 'colorblind',\n",
        "              order = mbti['type'].value_counts().index)\n",
        "\n",
        "for p in chart.patches:\n",
        "    chart.annotate(format(p.get_height(), '.0f'), \n",
        "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
        "                   ha = 'center', va = 'center', \n",
        "                   size=14,\n",
        "                   xytext = (0, 6), \n",
        "                   textcoords = 'offset points')\n",
        "\n",
        "plt.title('Personality Type Count in our Data',size=20)\n",
        "plt.xlabel('Type',size=17)\n",
        "plt.xticks(size=15)\n",
        "plt.ylabel('Count',size=17)\n",
        "plt.yticks(size=15)\n",
        "None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "ayRK9J6MUXzv",
        "outputId": "e2b87db6-8507-467e-e0a9-dffa00f0ee74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see here that the data is extremely skewed and in order for our models to get a good unbiased idea of each personality, we have decided to evenly sample each personality when prepping our data."
      ],
      "metadata": {
        "id": "QkNLwnSNxDUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepping Data"
      ],
      "metadata": {
        "id": "q2uz3LvFSsFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling Data"
      ],
      "metadata": {
        "id": "Dlul1jINWOG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data to get 180 instances of each personality\n",
        "types = list(mbti.type.unique())\n",
        "\n",
        "# creating a dict of dataframes containing each mbti\n",
        "dfs = dict()\n",
        "for typ in types:\n",
        "  dfs[typ] = mbti.loc[mbti.type == typ].iloc[:180]"
      ],
      "metadata": {
        "id": "ynspUujjVl09"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personalities = list(dfs.keys()) # list of all personalities\n",
        "del personalities[0] # removing INTJ for when concatinating into one dataframe"
      ],
      "metadata": {
        "id": "4G4UXlswWP15"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mbti_equal = dfs['INTJ']\n",
        "\n",
        "# concatinating into one dataframe\n",
        "for personality in personalities:\n",
        "  mbti_equal = pd.concat([mbti_equal,dfs[personality]])"
      ],
      "metadata": {
        "id": "e518G_O0Y5ei"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = mbti_equal.copy()\n",
        "df = df[['type','posts']]\n",
        "\n",
        "#df"
      ],
      "metadata": {
        "id": "LbZkobiOSifV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning Data"
      ],
      "metadata": {
        "id": "MwecTaZVWStu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_for(string):\n",
        "\n",
        "    \"\"\" Function which removes foreign chars from string \"\"\"\n",
        "    \n",
        "    foreign = re.compile(\"[\" \n",
        "                           u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           u\"\\U0001f926-\\U0001f937\"\n",
        "                           u\"\\U00010000-\\U0010ffff\"\n",
        "                           u\"\\u2640-\\u2642\" \n",
        "                           u\"\\u2600-\\u2B55\"\n",
        "                           u\"\\u200d\"\n",
        "                           u\"\\u23cf\"\n",
        "                           u\"\\u23e9\"\n",
        "                           u\"\\u231a\"\n",
        "                           u\"\\ufe0f\"  # dingbats\n",
        "                           u\"\\u3030\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return foreign.sub(r'', string) # return string without emojis"
      ],
      "metadata": {
        "id": "3rj6P6mBlpqM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_clean(s):\n",
        "\n",
        "  \"\"\" Removes double spaces and single letters. Then simply tokenizes using split function \"\"\"\n",
        "  \n",
        "  no_space =  re.sub('\\s+', ' ',s).strip()    \n",
        "  tkn_list = no_space.split()\n",
        "  sc_list=[word for word in tkn_list if len(word) != 1]\n",
        "  return sc_list"
      ],
      "metadata": {
        "id": "H67rKqY7UI18"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence(l):\n",
        "\n",
        "  \"\"\" Converts list of tokens into sentences \"\"\"\n",
        "  \n",
        "  empty = ''\n",
        "  for word in l:\n",
        "    empty = empty +' '+ word\n",
        "  return empty"
      ],
      "metadata": {
        "id": "kbxZfhTFYgwN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "OF9s6DxrbTla"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['posts'] = df['posts'].apply(remove_for)\n",
        "df['clean_tkn'] = df.posts.apply(token_clean)\n",
        "df['sentences'] = df.clean_tkn.apply(sentence)"
      ],
      "metadata": {
        "id": "3xzYBf7VPNZH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating labels for target values (type of personality)\n",
        "lbl = LabelEncoder()\n",
        "df['labels'] = lbl.fit_transform(df.type)"
      ],
      "metadata": {
        "id": "hz0CL5QhU2PR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "gySq-k5vcZOH",
        "outputId": "1a3df8bf-d772-4d6d-8583-218bc997b740"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index  type                                              posts  \\\n",
              "0         0  INTJ  know intj tool use interaction people excuse a...   \n",
              "1         1  INTJ  rap music ehh opp yeah know valid well know fa...   \n",
              "2         2  INTJ  preferably p hd low except wew lad video p min...   \n",
              "3         3  INTJ  drink like wish could drink red wine give head...   \n",
              "4         4  INTJ  space program ah bad deal meing freelance max ...   \n",
              "...     ...   ...                                                ...   \n",
              "2875  94108  INFP  wonder fuck crap happen lot point idea really ...   \n",
              "2876  94109  INFP  maybe enfj probably fe dom sjokz isfp deficio ...   \n",
              "2877  94110  INFP  say symptom mine im say infp people sort perso...   \n",
              "2878  94111  INFP  belief word sound like word someone close mind...   \n",
              "2879  94112  INFP  confuse process think hold lot merit read yes ...   \n",
              "\n",
              "                                              clean_tkn  \\\n",
              "0     [know, intj, tool, use, interaction, people, e...   \n",
              "1     [rap, music, ehh, opp, yeah, know, valid, well...   \n",
              "2     [preferably, hd, low, except, wew, lad, video,...   \n",
              "3     [drink, like, wish, could, drink, red, wine, g...   \n",
              "4     [space, program, ah, bad, deal, meing, freelan...   \n",
              "...                                                 ...   \n",
              "2875  [wonder, fuck, crap, happen, lot, point, idea,...   \n",
              "2876  [maybe, enfj, probably, fe, dom, sjokz, isfp, ...   \n",
              "2877  [say, symptom, mine, im, say, infp, people, so...   \n",
              "2878  [belief, word, sound, like, word, someone, clo...   \n",
              "2879  [confuse, process, think, hold, lot, merit, re...   \n",
              "\n",
              "                                              sentences  labels  \n",
              "0      know intj tool use interaction people excuse ...      10  \n",
              "1      rap music ehh opp yeah know valid well know f...      10  \n",
              "2      preferably hd low except wew lad video mind g...      10  \n",
              "3      drink like wish could drink red wine give hea...      10  \n",
              "4      space program ah bad deal meing freelance max...      10  \n",
              "...                                                 ...     ...  \n",
              "2875   wonder fuck crap happen lot point idea really...       9  \n",
              "2876   maybe enfj probably fe dom sjokz isfp deficio...       9  \n",
              "2877   say symptom mine im say infp people sort pers...       9  \n",
              "2878   belief word sound like word someone close min...       9  \n",
              "2879   confuse process think hold lot merit read yes...       9  \n",
              "\n",
              "[2880 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9ceacca-9576-4106-a996-2855bf76b68e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>clean_tkn</th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>know intj tool use interaction people excuse a...</td>\n",
              "      <td>[know, intj, tool, use, interaction, people, e...</td>\n",
              "      <td>know intj tool use interaction people excuse ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>rap music ehh opp yeah know valid well know fa...</td>\n",
              "      <td>[rap, music, ehh, opp, yeah, know, valid, well...</td>\n",
              "      <td>rap music ehh opp yeah know valid well know f...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>preferably p hd low except wew lad video p min...</td>\n",
              "      <td>[preferably, hd, low, except, wew, lad, video,...</td>\n",
              "      <td>preferably hd low except wew lad video mind g...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>drink like wish could drink red wine give head...</td>\n",
              "      <td>[drink, like, wish, could, drink, red, wine, g...</td>\n",
              "      <td>drink like wish could drink red wine give hea...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>space program ah bad deal meing freelance max ...</td>\n",
              "      <td>[space, program, ah, bad, deal, meing, freelan...</td>\n",
              "      <td>space program ah bad deal meing freelance max...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2875</th>\n",
              "      <td>94108</td>\n",
              "      <td>INFP</td>\n",
              "      <td>wonder fuck crap happen lot point idea really ...</td>\n",
              "      <td>[wonder, fuck, crap, happen, lot, point, idea,...</td>\n",
              "      <td>wonder fuck crap happen lot point idea really...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2876</th>\n",
              "      <td>94109</td>\n",
              "      <td>INFP</td>\n",
              "      <td>maybe enfj probably fe dom sjokz isfp deficio ...</td>\n",
              "      <td>[maybe, enfj, probably, fe, dom, sjokz, isfp, ...</td>\n",
              "      <td>maybe enfj probably fe dom sjokz isfp deficio...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2877</th>\n",
              "      <td>94110</td>\n",
              "      <td>INFP</td>\n",
              "      <td>say symptom mine im say infp people sort perso...</td>\n",
              "      <td>[say, symptom, mine, im, say, infp, people, so...</td>\n",
              "      <td>say symptom mine im say infp people sort pers...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2878</th>\n",
              "      <td>94111</td>\n",
              "      <td>INFP</td>\n",
              "      <td>belief word sound like word someone close mind...</td>\n",
              "      <td>[belief, word, sound, like, word, someone, clo...</td>\n",
              "      <td>belief word sound like word someone close min...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2879</th>\n",
              "      <td>94112</td>\n",
              "      <td>INFP</td>\n",
              "      <td>confuse process think hold lot merit read yes ...</td>\n",
              "      <td>[confuse, process, think, hold, lot, merit, re...</td>\n",
              "      <td>confuse process think hold lot merit read yes...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2880 rows  6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9ceacca-9576-4106-a996-2855bf76b68e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9ceacca-9576-4106-a996-2855bf76b68e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9ceacca-9576-4106-a996-2855bf76b68e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling"
      ],
      "metadata": {
        "id": "lmElq1D7syIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "XgbLalFT1A1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(df.posts, df.type):\n",
        "  train = df.loc[train_index] \n",
        "  test = df.loc[test_index] "
      ],
      "metadata": {
        "id": "0YHjSNvznVib"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X and y(target values) split for train and test\n",
        "X_train = train['sentences']\n",
        "y_train = train['labels']\n",
        "\n",
        "X_test = test['sentences']\n",
        "y_test = test['labels']"
      ],
      "metadata": {
        "id": "aRtjHsAl7WKA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifiers we want to test for\n",
        "bnb = BernoulliNB()\n",
        "cnb = ComplementNB()\n",
        "mnb = MultinomialNB()\n",
        "rf =  RandomForestClassifier()\n",
        "lg =  LogisticRegression()"
      ],
      "metadata": {
        "id": "noRYm1QCriNN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we've put our models into a list for autmoated training and testing\n",
        "models = [bnb, cnb, mnb, rf, lg] "
      ],
      "metadata": {
        "id": "3p0tLq1LtNi9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count Vectorizer"
      ],
      "metadata": {
        "id": "4VUqT9qSbe_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vect = CountVectorizer()\n",
        "train_sent_list = train['sentences'].to_list()\n",
        "train_countvec = vect.fit_transform(train_sent_list)\n",
        "test_countvec = vect.transform(test['sentences'])"
      ],
      "metadata": {
        "id": "Z_yTl-ms9vnX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_reports(models,train=True):\n",
        "  \"\"\" Prints precision, recall and f1 scores using countvec data using all models\"\"\"\n",
        "  for model in models:\n",
        "    model.fit(train_countvec, y_train)\n",
        "    \n",
        "    if train:\n",
        "      print('RESULTS FOR TRAINING SET')\n",
        "      print(model)\n",
        "      y_predict = model.predict(train_countvec)\n",
        "      print(classification_report(y_train,y_predict))\n",
        "      print('\\n\\n')\n",
        "\n",
        "    else:\n",
        "      print('RESULTS FOR TEST SET')\n",
        "      print(model)\n",
        "      y_predict = model.predict(test_countvec)\n",
        "      print(classification_report(y_test,y_predict))\n",
        "      print('\\n\\n')\n",
        "  "
      ],
      "metadata": {
        "id": "7K1IPQ_1uQq1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Set"
      ],
      "metadata": {
        "id": "djLEjNqXfIrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_reports(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-twddNA4sQp_",
        "outputId": "c24b08d1-669d-42cd-91bb-63f3dd45a186"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTS FOR TRAINING SET\n",
            "BernoulliNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       144\n",
            "           1       1.00      1.00      1.00       144\n",
            "           2       1.00      0.99      1.00       144\n",
            "           3       1.00      0.99      1.00       144\n",
            "           4       0.99      1.00      0.99       144\n",
            "           5       0.99      1.00      0.99       144\n",
            "           6       0.99      0.91      0.95       144\n",
            "           7       1.00      0.98      0.99       144\n",
            "           8       1.00      1.00      1.00       144\n",
            "           9       1.00      0.99      1.00       144\n",
            "          10       1.00      1.00      1.00       144\n",
            "          11       0.99      1.00      1.00       144\n",
            "          12       0.96      1.00      0.98       144\n",
            "          13       0.97      1.00      0.99       144\n",
            "          14       1.00      1.00      1.00       144\n",
            "          15       0.99      1.00      1.00       144\n",
            "\n",
            "    accuracy                           0.99      2304\n",
            "   macro avg       0.99      0.99      0.99      2304\n",
            "weighted avg       0.99      0.99      0.99      2304\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TRAINING SET\n",
            "ComplementNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98       144\n",
            "           1       1.00      1.00      1.00       144\n",
            "           2       1.00      0.99      1.00       144\n",
            "           3       1.00      1.00      1.00       144\n",
            "           4       1.00      1.00      1.00       144\n",
            "           5       1.00      1.00      1.00       144\n",
            "           6       0.96      1.00      0.98       144\n",
            "           7       1.00      1.00      1.00       144\n",
            "           8       1.00      1.00      1.00       144\n",
            "           9       1.00      1.00      1.00       144\n",
            "          10       1.00      1.00      1.00       144\n",
            "          11       1.00      1.00      1.00       144\n",
            "          12       1.00      1.00      1.00       144\n",
            "          13       0.99      1.00      1.00       144\n",
            "          14       1.00      1.00      1.00       144\n",
            "          15       1.00      1.00      1.00       144\n",
            "\n",
            "    accuracy                           1.00      2304\n",
            "   macro avg       1.00      1.00      1.00      2304\n",
            "weighted avg       1.00      1.00      1.00      2304\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TRAINING SET\n",
            "MultinomialNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       144\n",
            "           1       1.00      1.00      1.00       144\n",
            "           2       1.00      0.97      0.99       144\n",
            "           3       1.00      1.00      1.00       144\n",
            "           4       0.99      1.00      0.99       144\n",
            "           5       0.99      1.00      1.00       144\n",
            "           6       1.00      0.92      0.96       144\n",
            "           7       1.00      0.98      0.99       144\n",
            "           8       0.99      1.00      0.99       144\n",
            "           9       1.00      1.00      1.00       144\n",
            "          10       1.00      1.00      1.00       144\n",
            "          11       1.00      0.99      1.00       144\n",
            "          12       0.94      1.00      0.97       144\n",
            "          13       0.98      1.00      0.99       144\n",
            "          14       1.00      1.00      1.00       144\n",
            "          15       0.99      1.00      1.00       144\n",
            "\n",
            "    accuracy                           0.99      2304\n",
            "   macro avg       0.99      0.99      0.99      2304\n",
            "weighted avg       0.99      0.99      0.99      2304\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TRAINING SET\n",
            "RandomForestClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       144\n",
            "           1       1.00      1.00      1.00       144\n",
            "           2       1.00      1.00      1.00       144\n",
            "           3       1.00      1.00      1.00       144\n",
            "           4       1.00      1.00      1.00       144\n",
            "           5       1.00      1.00      1.00       144\n",
            "           6       1.00      1.00      1.00       144\n",
            "           7       1.00      1.00      1.00       144\n",
            "           8       1.00      1.00      1.00       144\n",
            "           9       1.00      1.00      1.00       144\n",
            "          10       1.00      1.00      1.00       144\n",
            "          11       1.00      1.00      1.00       144\n",
            "          12       1.00      1.00      1.00       144\n",
            "          13       1.00      1.00      1.00       144\n",
            "          14       1.00      1.00      1.00       144\n",
            "          15       1.00      1.00      1.00       144\n",
            "\n",
            "    accuracy                           1.00      2304\n",
            "   macro avg       1.00      1.00      1.00      2304\n",
            "weighted avg       1.00      1.00      1.00      2304\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TRAINING SET\n",
            "LogisticRegression()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       144\n",
            "           1       1.00      1.00      1.00       144\n",
            "           2       1.00      1.00      1.00       144\n",
            "           3       1.00      1.00      1.00       144\n",
            "           4       1.00      1.00      1.00       144\n",
            "           5       1.00      1.00      1.00       144\n",
            "           6       1.00      1.00      1.00       144\n",
            "           7       1.00      1.00      1.00       144\n",
            "           8       1.00      1.00      1.00       144\n",
            "           9       1.00      1.00      1.00       144\n",
            "          10       1.00      1.00      1.00       144\n",
            "          11       1.00      1.00      1.00       144\n",
            "          12       1.00      1.00      1.00       144\n",
            "          13       1.00      1.00      1.00       144\n",
            "          14       1.00      1.00      1.00       144\n",
            "          15       1.00      1.00      1.00       144\n",
            "\n",
            "    accuracy                           1.00      2304\n",
            "   macro avg       1.00      1.00      1.00      2304\n",
            "weighted avg       1.00      1.00      1.00      2304\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set"
      ],
      "metadata": {
        "id": "tmnMEw5wfSSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_reports(models, train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_0EqbO_fLdu",
        "outputId": "44627258-8e27-4188-842c-4399ca7a00d6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTS FOR TEST SET\n",
            "BernoulliNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.67      0.68        36\n",
            "           1       0.52      0.61      0.56        36\n",
            "           2       1.00      0.50      0.67        36\n",
            "           3       0.81      0.47      0.60        36\n",
            "           4       0.70      0.86      0.78        36\n",
            "           5       0.76      0.81      0.78        36\n",
            "           6       1.00      0.67      0.80        36\n",
            "           7       1.00      0.81      0.89        36\n",
            "           8       0.38      0.75      0.50        36\n",
            "           9       0.38      0.33      0.35        36\n",
            "          10       0.50      0.44      0.47        36\n",
            "          11       0.52      0.31      0.39        36\n",
            "          12       0.48      0.92      0.63        36\n",
            "          13       0.63      0.67      0.65        36\n",
            "          14       0.69      0.67      0.68        36\n",
            "          15       0.74      0.56      0.63        36\n",
            "\n",
            "    accuracy                           0.63       576\n",
            "   macro avg       0.68      0.63      0.63       576\n",
            "weighted avg       0.68      0.63      0.63       576\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TEST SET\n",
            "ComplementNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.68        36\n",
            "           1       0.57      0.69      0.62        36\n",
            "           2       0.90      0.78      0.84        36\n",
            "           3       0.81      0.58      0.68        36\n",
            "           4       0.74      0.97      0.84        36\n",
            "           5       0.92      0.94      0.93        36\n",
            "           6       0.94      0.94      0.94        36\n",
            "           7       0.69      1.00      0.82        36\n",
            "           8       0.58      0.53      0.55        36\n",
            "           9       0.63      0.47      0.54        36\n",
            "          10       0.54      0.58      0.56        36\n",
            "          11       0.45      0.28      0.34        36\n",
            "          12       0.67      0.86      0.76        36\n",
            "          13       0.89      0.92      0.90        36\n",
            "          14       0.75      0.83      0.79        36\n",
            "          15       0.89      0.67      0.76        36\n",
            "\n",
            "    accuracy                           0.73       576\n",
            "   macro avg       0.73      0.73      0.72       576\n",
            "weighted avg       0.73      0.73      0.72       576\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TEST SET\n",
            "MultinomialNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.68        36\n",
            "           1       0.48      0.75      0.59        36\n",
            "           2       0.96      0.61      0.75        36\n",
            "           3       0.81      0.61      0.70        36\n",
            "           4       0.65      0.89      0.75        36\n",
            "           5       0.78      0.86      0.82        36\n",
            "           6       1.00      0.67      0.80        36\n",
            "           7       0.97      0.92      0.94        36\n",
            "           8       0.43      0.64      0.52        36\n",
            "           9       0.56      0.42      0.48        36\n",
            "          10       0.61      0.56      0.58        36\n",
            "          11       0.59      0.47      0.52        36\n",
            "          12       0.52      0.86      0.65        36\n",
            "          13       0.75      0.75      0.75        36\n",
            "          14       0.86      0.69      0.77        36\n",
            "          15       0.83      0.56      0.67        36\n",
            "\n",
            "    accuracy                           0.68       576\n",
            "   macro avg       0.72      0.68      0.68       576\n",
            "weighted avg       0.72      0.68      0.68       576\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TEST SET\n",
            "RandomForestClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.75      0.72        36\n",
            "           1       0.61      0.64      0.62        36\n",
            "           2       0.68      0.89      0.77        36\n",
            "           3       0.57      0.47      0.52        36\n",
            "           4       0.75      0.83      0.79        36\n",
            "           5       0.74      0.72      0.73        36\n",
            "           6       0.97      0.94      0.96        36\n",
            "           7       0.66      0.97      0.79        36\n",
            "           8       0.60      0.50      0.55        36\n",
            "           9       0.56      0.53      0.54        36\n",
            "          10       0.47      0.44      0.46        36\n",
            "          11       0.62      0.42      0.50        36\n",
            "          12       0.85      0.81      0.83        36\n",
            "          13       0.76      0.81      0.78        36\n",
            "          14       0.72      0.78      0.75        36\n",
            "          15       0.77      0.56      0.65        36\n",
            "\n",
            "    accuracy                           0.69       576\n",
            "   macro avg       0.69      0.69      0.68       576\n",
            "weighted avg       0.69      0.69      0.68       576\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TEST SET\n",
            "LogisticRegression()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.69      0.71        36\n",
            "           1       0.86      0.69      0.77        36\n",
            "           2       0.66      0.81      0.73        36\n",
            "           3       0.63      0.75      0.68        36\n",
            "           4       0.88      0.81      0.84        36\n",
            "           5       0.82      0.78      0.80        36\n",
            "           6       0.94      0.81      0.87        36\n",
            "           7       0.92      0.92      0.92        36\n",
            "           8       0.58      0.53      0.55        36\n",
            "           9       0.68      0.64      0.66        36\n",
            "          10       0.55      0.58      0.57        36\n",
            "          11       0.51      0.61      0.56        36\n",
            "          12       0.71      0.69      0.70        36\n",
            "          13       0.77      0.83      0.80        36\n",
            "          14       0.76      0.81      0.78        36\n",
            "          15       0.78      0.69      0.74        36\n",
            "\n",
            "    accuracy                           0.73       576\n",
            "   macro avg       0.74      0.73      0.73       576\n",
            "weighted avg       0.74      0.73      0.73       576\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF Vectorizer"
      ],
      "metadata": {
        "id": "R1y5vykea_bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
        "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
        "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "6tF6SVWKfN3P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
        "\n",
        "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "def tf_idf_reports(models,train=True):\n",
        "  \"\"\" prints precision, recall and f1 scores using tf-idf data \"\"\"\n",
        "  for model in models:\n",
        "    model.fit(X_train_vectors_tfidf, y_train)\n",
        "    if train:\n",
        "      print('RESULTS FOR TRAINING SET')\n",
        "      print(model)\n",
        "      y_predict = model.predict(X_train_vectors_tfidf)\n",
        "      print(classification_report(y_train,y_predict))\n",
        "      print('\\n\\n')\n",
        "\n",
        "    else:\n",
        "      print('RESULTS FOR TEST SET')\n",
        "      print(model)\n",
        "      y_predict = model.predict(X_test_vectors_tfidf)\n",
        "      print(classification_report(y_test,y_predict))\n",
        "      print('\\n\\n')\n"
      ],
      "metadata": {
        "id": "eMdBLH61vhyN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Set"
      ],
      "metadata": {
        "id": "mm1v_zzNkGTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf_reports(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0LJnhnHyDSg",
        "outputId": "5b77cdc4-6f55-4117-9ce5-e2a549535b0f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTS FOR TRAINING SET\n",
            "BernoulliNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       144\n",
            "           1       1.00      1.00      1.00       144\n",
            "           2       1.00      0.99      1.00       144\n",
            "           3       1.00      0.99      1.00       144\n",
            "           4       0.99      1.00      0.99       144\n",
            "           5       0.99      1.00      0.99       144\n",
            "           6       0.99      0.91      0.95       144\n",
            "           7       1.00      0.98      0.99       144\n",
            "           8       1.00      1.00      1.00       144\n",
            "           9       1.00      0.99      1.00       144\n",
            "          10       1.00      1.00      1.00       144\n",
            "          11       0.99      1.00      1.00       144\n",
            "          12       0.96      1.00      0.98       144\n",
            "          13       0.97      1.00      0.99       144\n",
            "          14       1.00      1.00      1.00       144\n",
            "          15       0.99      1.00      1.00       144\n",
            "\n",
            "    accuracy                           0.99      2304\n",
            "   macro avg       0.99      0.99      0.99      2304\n",
            "weighted avg       0.99      0.99      0.99      2304\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TRAINING SET\n",
            "ComplementNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97       144\n",
            "           1       1.00      0.99      1.00       144\n",
            "           2       1.00      0.99      1.00       144\n",
            "           3       1.00      1.00      1.00       144\n",
            "           4       0.99      1.00      0.99       144\n",
            "           5       1.00      1.00      1.00       144\n",
            "           6       0.95      0.98      0.96       144\n",
            "           7       0.99      0.99      0.99       144\n",
            "           8       0.99      1.00      1.00       144\n",
            "           9       1.00      1.00      1.00       144\n",
            "          10       1.00      0.99      0.99       144\n",
            "          11       1.00      1.00      1.00       144\n",
            "          12       0.99      1.00      1.00       144\n",
            "          13       0.99      1.00      1.00       144\n",
            "          14       1.00      0.99      1.00       144\n",
            "          15       1.00      1.00      1.00       144\n",
            "\n",
            "    accuracy                           0.99      2304\n",
            "   macro avg       0.99      0.99      0.99      2304\n",
            "weighted avg       0.99      0.99      0.99      2304\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TRAINING SET\n",
            "MultinomialNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       144\n",
            "           1       0.88      1.00      0.94       144\n",
            "           2       1.00      0.90      0.95       144\n",
            "           3       1.00      0.90      0.95       144\n",
            "           4       0.96      0.99      0.98       144\n",
            "           5       0.88      1.00      0.94       144\n",
            "           6       1.00      0.82      0.90       144\n",
            "           7       0.99      0.92      0.95       144\n",
            "           8       0.89      1.00      0.94       144\n",
            "           9       0.99      0.98      0.99       144\n",
            "          10       1.00      0.92      0.96       144\n",
            "          11       1.00      0.93      0.96       144\n",
            "          12       0.80      1.00      0.89       144\n",
            "          13       0.97      0.99      0.98       144\n",
            "          14       1.00      0.99      1.00       144\n",
            "          15       1.00      0.89      0.94       144\n",
            "\n",
            "    accuracy                           0.95      2304\n",
            "   macro avg       0.96      0.95      0.95      2304\n",
            "weighted avg       0.96      0.95      0.95      2304\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TRAINING SET\n",
            "RandomForestClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       144\n",
            "           1       1.00      1.00      1.00       144\n",
            "           2       1.00      1.00      1.00       144\n",
            "           3       1.00      1.00      1.00       144\n",
            "           4       1.00      1.00      1.00       144\n",
            "           5       1.00      1.00      1.00       144\n",
            "           6       1.00      1.00      1.00       144\n",
            "           7       1.00      1.00      1.00       144\n",
            "           8       1.00      1.00      1.00       144\n",
            "           9       1.00      1.00      1.00       144\n",
            "          10       1.00      1.00      1.00       144\n",
            "          11       1.00      1.00      1.00       144\n",
            "          12       1.00      1.00      1.00       144\n",
            "          13       1.00      1.00      1.00       144\n",
            "          14       1.00      1.00      1.00       144\n",
            "          15       1.00      1.00      1.00       144\n",
            "\n",
            "    accuracy                           1.00      2304\n",
            "   macro avg       1.00      1.00      1.00      2304\n",
            "weighted avg       1.00      1.00      1.00      2304\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TRAINING SET\n",
            "LogisticRegression()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       144\n",
            "           1       0.99      0.99      0.99       144\n",
            "           2       0.99      0.99      0.99       144\n",
            "           3       0.99      1.00      1.00       144\n",
            "           4       0.99      0.98      0.98       144\n",
            "           5       1.00      1.00      1.00       144\n",
            "           6       1.00      0.95      0.98       144\n",
            "           7       0.99      0.99      0.99       144\n",
            "           8       0.97      0.99      0.98       144\n",
            "           9       0.99      1.00      0.99       144\n",
            "          10       0.98      0.98      0.98       144\n",
            "          11       0.99      0.99      0.99       144\n",
            "          12       0.97      0.99      0.98       144\n",
            "          13       0.98      0.99      0.99       144\n",
            "          14       0.98      0.99      0.99       144\n",
            "          15       1.00      0.99      0.99       144\n",
            "\n",
            "    accuracy                           0.99      2304\n",
            "   macro avg       0.99      0.99      0.99      2304\n",
            "weighted avg       0.99      0.99      0.99      2304\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test Set"
      ],
      "metadata": {
        "id": "tUFI_X4DkMbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf_reports(models, train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKu4xHKxgAwK",
        "outputId": "5e23e0f4-a0c7-450f-e5a1-e8d87317edbb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTS FOR TEST SET\n",
            "BernoulliNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.67      0.68        36\n",
            "           1       0.52      0.61      0.56        36\n",
            "           2       1.00      0.50      0.67        36\n",
            "           3       0.81      0.47      0.60        36\n",
            "           4       0.70      0.86      0.78        36\n",
            "           5       0.76      0.81      0.78        36\n",
            "           6       1.00      0.67      0.80        36\n",
            "           7       1.00      0.81      0.89        36\n",
            "           8       0.38      0.75      0.50        36\n",
            "           9       0.38      0.33      0.35        36\n",
            "          10       0.50      0.44      0.47        36\n",
            "          11       0.52      0.31      0.39        36\n",
            "          12       0.48      0.92      0.63        36\n",
            "          13       0.63      0.67      0.65        36\n",
            "          14       0.69      0.67      0.68        36\n",
            "          15       0.74      0.56      0.63        36\n",
            "\n",
            "    accuracy                           0.63       576\n",
            "   macro avg       0.68      0.63      0.63       576\n",
            "weighted avg       0.68      0.63      0.63       576\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TEST SET\n",
            "ComplementNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.72      0.74        36\n",
            "           1       0.52      0.75      0.61        36\n",
            "           2       0.94      0.81      0.87        36\n",
            "           3       0.78      0.39      0.52        36\n",
            "           4       0.73      0.92      0.81        36\n",
            "           5       0.79      0.94      0.86        36\n",
            "           6       0.97      0.94      0.96        36\n",
            "           7       0.78      1.00      0.88        36\n",
            "           8       0.52      0.67      0.59        36\n",
            "           9       0.57      0.36      0.44        36\n",
            "          10       0.48      0.42      0.45        36\n",
            "          11       0.50      0.25      0.33        36\n",
            "          12       0.71      0.89      0.79        36\n",
            "          13       0.89      0.89      0.89        36\n",
            "          14       0.71      0.81      0.75        36\n",
            "          15       0.81      0.72      0.76        36\n",
            "\n",
            "    accuracy                           0.72       576\n",
            "   macro avg       0.72      0.72      0.70       576\n",
            "weighted avg       0.72      0.72      0.70       576\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TEST SET\n",
            "MultinomialNB()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67        36\n",
            "           1       0.31      0.83      0.45        36\n",
            "           2       1.00      0.44      0.62        36\n",
            "           3       0.86      0.17      0.28        36\n",
            "           4       0.79      0.83      0.81        36\n",
            "           5       0.45      0.92      0.61        36\n",
            "           6       1.00      0.64      0.78        36\n",
            "           7       1.00      0.72      0.84        36\n",
            "           8       0.28      0.61      0.39        36\n",
            "           9       0.87      0.36      0.51        36\n",
            "          10       0.83      0.14      0.24        36\n",
            "          11       0.40      0.06      0.10        36\n",
            "          12       0.38      0.89      0.53        36\n",
            "          13       0.84      0.75      0.79        36\n",
            "          14       0.83      0.53      0.64        36\n",
            "          15       0.88      0.39      0.54        36\n",
            "\n",
            "    accuracy                           0.56       576\n",
            "   macro avg       0.71      0.56      0.55       576\n",
            "weighted avg       0.71      0.56      0.55       576\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TEST SET\n",
            "RandomForestClassifier()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.72      0.69        36\n",
            "           1       0.52      0.72      0.60        36\n",
            "           2       0.79      0.75      0.77        36\n",
            "           3       0.71      0.33      0.45        36\n",
            "           4       0.84      0.75      0.79        36\n",
            "           5       0.50      0.78      0.61        36\n",
            "           6       1.00      0.94      0.97        36\n",
            "           7       0.65      0.94      0.77        36\n",
            "           8       0.33      0.33      0.33        36\n",
            "           9       0.56      0.50      0.53        36\n",
            "          10       0.44      0.42      0.43        36\n",
            "          11       0.44      0.33      0.38        36\n",
            "          12       0.59      0.64      0.61        36\n",
            "          13       0.71      0.67      0.69        36\n",
            "          14       0.64      0.69      0.67        36\n",
            "          15       0.76      0.44      0.56        36\n",
            "\n",
            "    accuracy                           0.62       576\n",
            "   macro avg       0.64      0.62      0.62       576\n",
            "weighted avg       0.64      0.62      0.62       576\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RESULTS FOR TEST SET\n",
            "LogisticRegression()\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.78      0.78        36\n",
            "           1       0.73      0.75      0.74        36\n",
            "           2       0.83      0.83      0.83        36\n",
            "           3       0.81      0.72      0.76        36\n",
            "           4       0.97      0.86      0.91        36\n",
            "           5       0.84      0.89      0.86        36\n",
            "           6       1.00      0.83      0.91        36\n",
            "           7       0.87      0.92      0.89        36\n",
            "           8       0.59      0.64      0.61        36\n",
            "           9       0.70      0.64      0.67        36\n",
            "          10       0.54      0.69      0.61        36\n",
            "          11       0.74      0.72      0.73        36\n",
            "          12       0.82      0.89      0.85        36\n",
            "          13       0.82      0.92      0.87        36\n",
            "          14       0.89      0.86      0.87        36\n",
            "          15       0.87      0.72      0.79        36\n",
            "\n",
            "    accuracy                           0.79       576\n",
            "   macro avg       0.80      0.79      0.79       576\n",
            "weighted avg       0.80      0.79      0.79       576\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resutls and Conclusion"
      ],
      "metadata": {
        "id": "uxaHpxPKeWZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, we can see that we have extremely high metrics scores on the training sets and noticably lower scores on the test sets. This definitely indicates our model overfitting the data. Despite this we are still achieving good f1 scores of over **70%** in both the count vectorizer and tf-idf methods. Going forward we will attempt to reduce this via regularization, to create a more robust final model. \n",
        "\n",
        "We also noted that in the preparation of our data we have cut a large portion of our data to avoid the skewed distribution. This meant we cut out a large portion of valuable data out. We would like to implement oversampling in our future versions to avoid loosing such valuable information.\n",
        "\n",
        "In summary, there are many optimizations to be still made and a final method the Word2vec method we found during our research into creating meaning from strings for machines that we would like to explore further. Given this was our first NLP project with us being fairly new to it and a given time limit. We are very happy with the base models that we have outputted thus far. "
      ],
      "metadata": {
        "id": "4CFTX9XKhTjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-gn-x0DgkU2X"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}